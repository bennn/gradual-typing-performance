This is not your usual POPL paper, thanks for the consideration.

GT: SOUND Gradual Typing 
TR: Typed Racket 
JIT Just in time compiler 

**********************************************************************
*** Are our results already known in light of your previous work? ***
**********************************************************************

SOUND GT follows from a distinguished series of foundational works:

 SFP 2006 and DLS 2006
 ECOOP 2007, ESOP 2009
 POPL 2008, 2010, 2011, 2x 2015
 PLDI 2015

This paper is the first to present any evaluation of the gradual typing
approach at all. While we used the idea in our OWN ECOOP paper for two
small benchmarks, nothing in this paper explains/motivates the framework.

The experimental results are for a mature implementation of gradual typing
with a large user base (commercial!) on independently created programs,
representative of idiomatic usage of TR.

Our results point to a FUNDAMENTAL CHALLENGE to the ENTIRE LINE OF WORK.
As such, they are a call to arms for designers and implementers..

**********************************************************************
*** Are our results of limited applicability due to our choice of ****
***  experimental environment? ***************************************
**********************************************************************

* #81A laments the lack of attention of mico-level gradual typing.

We tried! There is no robust implementations with rich libraries of GT.

* #81A asks if choosing TR biases experiments and endanger our conclusions.

TR is representative of an approach to GT that goes back to the 2 Ur-papers
from 2006.  Any language that tags values with the casts applied to them
behave similarly to TR: there will be allocations when the casts are
applied; indirections to access data; and checks at use points.  TR
implementation is NOT a naive implementation of GT. It includes a JIT and
many optimizations. 

* #81A asks about the performance of TypeScript.

TypeScript is UNSOUND (!!!!).  The underlying JavaScript VM sees the same
code for each configuration in our lattice.

StrongScript (by Vitek) has low overheads for partial checks, but it
remains UNSOUND..

* #81B makes a point about the impossibility of a negative result without
* evaluating the potential benefits of JITs.

The primary result is a framework. The negative evaluations for the most
mature implementation of GT is a validation of its usefulness. 

TR does have a JIT, but the JIT is not aware of gradual types.  

What impact MIGHT hypothetical GT-aware optimizations have on performance?
The cost of GT split in three:
-- cast:- requires allocation
-- unprotected access: may be slower as any value may have a contract
-- protected access: checks must be run

There is NO LOCALITY the JIT can leverage. A value cast in one part of the
program must flow through the code, through modules, and is accessed pretty
much anywhere. There are NO EXISTING optimization that would avoid these
costs in the presence of dynamic features. 

* The reviewer ask about an evaluation using Safe Typescript programs.

We have not done this. We note in the paper that a 77x slowdown was reported
by the authors in case of a fully dynamic program, so it is likely that an
application of our framework would yield similarly frightening results. 

Our paper is a challenge to other implementors of GT to evaluate their work
properly before flooding POPL with more theoretical papers. The effort of
applying our framework is HUGE and requires a substantial team. MS may have
that; we don't. 

* #81B states that N-deliverability, N/M-usability are unhelpful as the
* performance of gradual typing is so bad that there is no point to them.

* #81B also states that 50% overhead is likely the maximum acceptable.

The very reason for this formulation is that any user can pick a threshold.
If 50% is what is required than clearly GT in its present form is dead.  No
JIT optimizations will save us.  For TR, we have users that still use GT,
but that may be the peculiarities of one community.

Our point is that if someone finds a solution that speeds up GT, this is the
framework to evaluate that solution.

***************************************************************************
*** More insights would be appreciated ************************************
***************************************************************************

* #81A asks for constructive suggestions and solutions.

GT is a 10+ research investment. The magnitude of the overheads and the ease
with which a programmer can fall off a performance cliff came as a SHOCK.
This paper's role is to stand as a warning to others in the field, and to
provide with a methodology that other can follow to evaluate their
implementations.

* #81B+#81A ask for details about what kinds of checks are expensive.

We now do have these results and -- with the permission of the committee
AFTER THE PAPER IS ACCEPTED AS IS -- we will add them. 

***************************************************************************
********** Reviewer #81C **************************************************
***************************************************************************

* Who wote the programs that you study?

All the programs in the study were existing Racket/TR programs that have
been used by others.

Their authorship is:

- LIST HERE

* You talk about "adapting" existing programs. 

The adaptations were the addition of type annotations for Racket program and
their removal for TR programs.

* When typing a module in TR, is there just one choice of typing?

One point that we would like to clarify here is that, indeed, there is more
than one way to add types to our TR benchmarks. We expect that
this is true to some extent for any practical gradual type system and that a
subjective choice must be made. We will address this in our paper.

* From your benchmark descriptions it does *not* appear that the programs
* you study are at the scale where they would be implemented by teams. 

Good point, we will clarify.

* The "Gregor" benchmark sounds totally synthetic.

...

* A problem I have with the definition of L-step N/M-usable is that
* two different modules may vary dramatically in their size and their
* ease of typability. 

In TR, types are put on the interface of modules. So the while your point is
correct, modules that export more definitions require more annotations, it
is worth pointing out that these annotations are not proportional to the
size of the modules in lines of code.


* In your discussion of Fig. 3 you say "Almost all partially typed
  configurations exhibit slowdowns between 0.7x and 105x."  First, 0.7x is
  the speedup associated with having full types.  Second, I could not see
  (from Fig. 3) any exceptions to this range.  If there are exceptions,
  please comment on a couple of them.  If there are no exceptions then I'm
  not sure what point you are making here other than commenting on the range
  associated with the figure.

?? Minor ??? Ignore

* I got confused by your statement: "These modules make up a tightly coupled
  clique."  By "clique" I thought you meant that the graph of inter-module
  dependences would be the complete graph.  But looking at Figure 1, the
  module structures all appear to be DAGs.  So there are no cycles between
  modules, and thus modules cannot form cliques.

A boundary crossing happens when a value from one module is used by code in the
other. In the case that a function is exported from A to B, then calls to that
function in B will cause B values to flow into the body of the function in A.
 and B if B depends on A but not vice-versa" <-- should clarify this in response


* I found your inclusion of quad in Figure 5 misleading - it would have been
* clearer to use dashes in the figure to indicate that there was no data.

Good point.

* "Our results may be less valid in the context of large programs, though
*  practical experience using TR suggests otherwise."  - this statement is
*  vague and mysterious to the reader.  

??


* In 3.1.1 ... it wasn't clear to me whether you had to manually adapt the
*  benchmarks to use adaptors, or whether this was somehow done
*  automatically.  This became clearer later, but I think you could explain
*  more clearly at this point that you did have to manually edit benchmarks.

We will clarify.

* To what extent can type inference help in inferring types for modules?

This is an interesting idea, we will consider it. Thanks!

* It's cool to have done exhaustive consideration of typed configurations,
* but, as you remark, this is not feasible for larger programs. Why not
* choose random paths.

Random walks is one of the many, many things we have tried when doing this
research.  It is certainly something that one would do to scale our approach
to situations with much larger search spaces (either massive systems, or
micro-level GT), but for this paper we wanted to give an exhaustive view of
the space of configurations to convince the readers that we were not cherry
pickig bad ones.
