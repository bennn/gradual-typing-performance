This is not your usual POPL paper, thanks for the consideration.

Gradual Typing = GT
Typed Racket = TR
Just in time compiler = JIT

**********************************************************************
*** Are our results already known in light of previous work? *********
**********************************************************************

* Reviewers #81A+#81B remark we published performance results at
* ECOOP'15~[24] and question novelty as well lessons learned.

This is the first attempt to systematically evaluate the costs of the sound
gradual typing approach. Sound GT follows from a distinguished series of
foundational works:

- Siek & Taha,        SFP 2006
- Tobin-Hochstadt ea, DLS 2006
- Siek & Taha,        ECOOP 2007
- Tobin-Hochstadt ea, POPL 2008
- Siek ea,            ESOP 2009
- Siek ea,            POPL 2010
- Amal ea,            POPL 2011
- Garcia ea,          POPL 2015
- Greenberg ea        POPL 2015
- Siek ea,            PLDI 2015

We provide experimental results for a mature implementation of gradual
typing (TR is used by more than us) on independently written programs
representative of idiomatic usage of TR.

Our results point to a fundamental challenge to the entire line of work, one
that must absolutely be addressed if the approach is to succeed.

This paper is a call to arms to language designers (are there other sound
designs?)  and language implementers (can optimizations mitigate costs?).

We view our results as opening new research directions!

**********************************************************************
*** Are our results of limited applicability due to our choice of ****
***  experimental environment? ***************************************
**********************************************************************

* #81A laments the lack of attention of mico-level gradual typing.

One reason for this is the lack of robust implementations with rich
libraries. We tried some prototypes but they were too fragile or too
impoverished to run the range of programs that we were interested in
evaluating. (Eg. no concurrency, no graphics, no...)

* #81A asks if choosing TR biases experiments and endanger our conclusions.

TR is representative of an approach to sound GT that goes back to Siek et
al. and Tobin-Hochstadt et al.  Any language that tags values with the casts
applied to them will behave similarly to TR: namely there will be allocation
costs when the casts are applied, indirections to access data, and finally
checks at use points.  The TR implementation is far from a naive
implementation of GT, many optimizations have been implemented in the
contract system, and the TR JIT does help.

* #81A asks about the performance of TypeScript.

TypeScript is unsound, types are erased, thus there will be no difference
between any of the versions.  The underlying JavaScript VM will see the same
code for each configuration in our lattice.

One of the authors implemented StrongScript [Richards, ECOOP 15] which had
low overheads. But again it is unsound (with some sound patches, but this a
weaker guarantee).

* #81B makes a point about the impossibility of a negative result without
* evaluating the potential benefits of JITs.

TR does have a JIT, which was turned on during our experiments. But the JIT
is not aware of gradual types.

So the question is: can we speculate what impact would hypothetical GT-aware
optimizations have on performance?

The cost of GT split in three:

 - cast  -- requires allocation

 - unprotected access -- may be slower as any value may have a contract

 - protected access -- checks must be run

There is no locality the JIT can leverage. A value cast in one part of the
program can (and does!) flow through the code, through modules, and is
accessed pretty much anywhere.  We can't think of an optimization that would
avoid these costs yet support dynamic features such as eval. We can imagine
attenuating them to some extent, but only up to a point.

* The reviewer ask about an evaluation using Safe Typescript programs.

We have not done this. We note in the paper that a 77x slowdown was reported
by the authors in case of a fully dynamic program, so it would not be
surprising if our results carried over.  But we cannot tell for sure.  The
main challenge would be to develop a benchmark suite of interesting programs
in STS.  Porting our code is unlikely to work as JavaScript does not have
the libraries (graphics) or the threading support that would be required for
direct ports. One could fall back to something like the "Language
performance Game" which has codes in all possible languages, but our
experience with them (we used them to evaluate an implementation of R in
VEE'14) is that they are a poor substitute for real codes written in an
idiomatic style.

* #81B states that N-deliverability, N/M-usability are unhelpful as the
* performance of gradual typing is so bad that there is no point to them.

* #81B states that 50% overhead is likely the maximum acceptable.

The very reason for this formulation is that any user can pick his or her
threshold.  If 50% is what is required than clearly GT in its present form
is dead.  No JIT optimizations will save us.  For TR, we have users that
still use GT, but that may be the peculiarities of one community.

Our point is that if someone finds a solution that speeds up GT, this is the
framework to evaluate that solution.

***************************************************************************
*** More insights would be appreciated ************************************
***************************************************************************

* #81A asks for constructive suggestions and solutions.

GT is a 10+ research investment. The magnitude of the overheads and the ease
with which a programmer can fall off a performance cliff came as a shock.
This paper's role is to stand as a warning to others in the field, and to
provide with a methodology that other can follow to evaluate their
implementations.

* #81B+#81A ask for details about what kinds of checks are expensive.

We do have these results and will add them, space permitting. Since we
cannot introduce new results here, let's just say that each benchmark has
its own flavor with different cost centers.


***************************************************************************
********** Reviewer #81C **************************************************
***************************************************************************

* Who wote the programs that you study?

All the programs in the study were existing Racket/TR programs that have
been used by others.

Their authorship is:

- LIST HERE

* You talk about "adapting" existing programs. 

The adaptations were the addition of type annotations for Racket program and
their removal for TR programs.

* When typing a module in TR, is there just one choice of typing?

One point that we would like to clarify here is that, indeed, there is more
than one way to add types to our TR benchmarks. We expect that
this is true to some extent for any practical gradual type system and that a
subjective choice must be made. We will address this in our paper.

* From your benchmark descriptions it does *not* appear that the programs
* you study are at the scale where they would be implemented by teams. 

Good point, we will clarify.

* The "Gregor" benchmark sounds totally synthetic.

...

* A problem I have with the definition of L-step N/M-usable is that
* two different modules may vary dramatically in their size and their
* ease of typability. 

In TR, types are put on the interface of modules. So the while your point is
correct, modules that export more definitions require more annotations, it
is worth pointing out that these annotations are not proportional to the
size of the modules in lines of code.


* In your discussion of Fig. 3 you say "Almost all partially typed
  configurations exhibit slowdowns between 0.7x and 105x."  First, 0.7x is
  the speedup associated with having full types.  Second, I could not see
  (from Fig. 3) any exceptions to this range.  If there are exceptions,
  please comment on a couple of them.  If there are no exceptions then I'm
  not sure what point you are making here other than commenting on the range
  associated with the figure.

?? Minor ??? Ignore

* I got confused by your statement: "These modules make up a tightly coupled
  clique."  By "clique" I thought you meant that the graph of inter-module
  dependences would be the complete graph.  But looking at Figure 1, the
  module structures all appear to be DAGs.  So there are no cycles between
  modules, and thus modules cannot form cliques.

A boundary crossing happens when a value from one module is used by code in the
other. In the case that a function is exported from A to B, then calls to that
function in B will cause B values to flow into the body of the function in A.
 and B if B depends on A but not vice-versa" <-- should clarify this in response


* I found your inclusion of quad in Figure 5 misleading - it would have been
* clearer to use dashes in the figure to indicate that there was no data.

Good point.

* "Our results may be less valid in the context of large programs, though
*  practical experience using TR suggests otherwise."  - this statement is
*  vague and mysterious to the reader.  

??


* In 3.1.1 ... it wasn't clear to me whether you had to manually adapt the
*  benchmarks to use adaptors, or whether this was somehow done
*  automatically.  This became clearer later, but I think you could explain
*  more clearly at this point that you did have to manually edit benchmarks.

We will clarify.

* To what extent can type inference help in inferring types for modules?

This is an interesting idea, we will consider it. Thanks!

* It's cool to have done exhaustive consideration of typed configurations,
* but, as you remark, this is not feasible for larger programs. Why not
* choose random paths.

Random walks is one of the many, many things we have tried when doing this
research.  It is certainly something that one would do to scale our approach
to situations with much larger search spaces (either massive systems, or
micro-level GT), but for this paper we wanted to give an exhaustive view of
the space of configurations to convince the readers that we were not cherry
pickig bad ones.
